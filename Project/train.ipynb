{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "loqLueA6ZjsN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.cuda\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import requests, tarfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaGoxjrxZjsS",
        "outputId": "15484542-a987-4538-b645-eb7ab61f3def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FddWCNRzZjsU",
        "outputId": "8b1ecb39-095a-499e-fb32-2c3efe2a1c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading UTKFace...\n",
            "Download complete.\n"
          ]
        }
      ],
      "source": [
        "dataPath = 'UTKFace'\n",
        "if (dataPath not in os.listdir()):\n",
        "    print(\"Downloading UTKFace...\")\n",
        "    url = \"https://drive.google.com/uc?export=download&id=0BxYys69jI14kYVM3aVhKS1VhRUk&confirm=t&uuid=f981ca1d-ba0f-40c9-a4a0-8eaa887f3b6d&at=ANzk5s7e36SgjT0FlqBbRiijefRg:1681897584880\"\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    file = tarfile.open(fileobj=response.raw, mode=\"r|gz\")\n",
        "    file.extractall(path=\".\")\n",
        "    print(\"Download complete.\")\n",
        "else:\n",
        "    print(\"UTKFace already downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p808DasNdMtZ"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataPath, transform=None):\n",
        "        self.dataPath = dataPath\n",
        "        self.transform = transform\n",
        "        #self.imagePaths = [f for f in os.listdir(self.dataPath) if f.endswith('.jpg')]\n",
        "        self.imagePaths = [f for f in os.listdir(self.dataPath) if f.endswith('.jpg') and f.split('_')[2] != '4']\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        imagePath = self.imagePaths[index]\n",
        "        try:\n",
        "            imageTensor = torchvision.io.read_image(f'{self.dataPath}/{imagePath}').float()\n",
        "            fileName = imagePath.split('_')\n",
        "            label = torch.Tensor([int(fileName[0]), int(fileName[1]), int(fileName[2])])\n",
        "            if self.transform:\n",
        "                imageTensor = self.transform(imageTensor)\n",
        "            return imageTensor, label\n",
        "        except:\n",
        "            return self.__getitem__((index + 1) % len(self.imagePaths))\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imagePaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFTvbBTeZjsX",
        "outputId": "25a2200d-1383-4c1b-9975-5c74eb77f15e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22016 15411 4404 2201\n"
          ]
        }
      ],
      "source": [
        "# Resize and normalizde\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize(224, antialias=True),\n",
        "     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "dataset = MyDataset(dataPath, transform=transform)\n",
        "\n",
        "batchSize = 100\n",
        "testSplit = 0.1 # use 10% of dataset as test\n",
        "validSplit = 0.2 / (1-testSplit) # use 20% of dataset as validation\n",
        "\n",
        "testSize = int(np.floor(len(dataset)*testSplit))\n",
        "trainValidSize = len(dataset) - testSize\n",
        "validSize = int(np.ceil(trainValidSize*validSplit))\n",
        "trainSize = trainValidSize - validSize\n",
        "print(len(dataset), trainSize, validSize, testSize)\n",
        "\n",
        "trainValidSet, testSet = torch.utils.data.random_split(dataset, [trainValidSize, testSize])\n",
        "trainSet, validSet = torch.utils.data.random_split(trainValidSet, [trainSize, validSize])\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=batchSize, shuffle=True)\n",
        "validLoader = torch.utils.data.DataLoader(validSet, batch_size=batchSize, shuffle=True)\n",
        "testLoader = torch.utils.data.DataLoader(testSet, batch_size=batchSize, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rOCaZIQkZjsY"
      },
      "outputs": [],
      "source": [
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNetModel,self).__init__()\n",
        "        self.resnet = torchvision.models.resnet34(pretrained=True)\n",
        "        for param in self.resnet.parameters():\n",
        "            param.requires_grad=False\n",
        "        self.resnet.fc = nn.Linear(512, 512)\n",
        "        self.ageHidden = nn.Linear(512,512)\n",
        "        self.genderHidden = nn.Linear(512,512)\n",
        "        self.ethnicityHidden = nn.Linear(512,512)\n",
        "        self.ageFc = nn.Linear(512,1)\n",
        "        self.genderFc = nn.Linear(512,2)\n",
        "        #self.ethnicityFc = nn.Linear(512,5)\n",
        "        self.ethnicityFc = nn.Linear(512,4)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        resOut = F.relu(self.resnet.forward(x))\n",
        "        ageX = F.relu(self.ageHidden(resOut))\n",
        "        ageOut = self.ageFc(ageX)\n",
        "        genderX = F.relu(self.genderHidden(resOut))\n",
        "        genderOut = F.sigmoid(self.genderFc(genderX))\n",
        "        ethnicityX = F.relu(self.ethnicityHidden(resOut))\n",
        "        ethnicityOut = F.softmax(self.ethnicityFc(ethnicityX), dim=1)\n",
        "        return ageOut, genderOut, ethnicityOut\n",
        "\n",
        "    def unfreeze(self):\n",
        "        for param in self.resnet.parameters():\n",
        "            param.requires_grad=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EyEWr79LZjsY"
      },
      "outputs": [],
      "source": [
        "# ResNetModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PPTkQJzyZjsY"
      },
      "outputs": [],
      "source": [
        "def lossAge(predictAge, targetAge):\n",
        "    loss = torch.sqrt(F.mse_loss(predictAge, targetAge))\n",
        "    #mask = ((targetAge >= 20) & (targetAge <= 30)).float()\n",
        "    #loss = loss * (1.0 - (mask * 0.5))\n",
        "    return loss\n",
        "\n",
        "def lossGender(predictGender, targetGender):\n",
        "    loss = F.binary_cross_entropy(predictGender, targetGender)\n",
        "    return loss\n",
        "\n",
        "def lossEthnicity(predictEthnicity, targetEthnicity):\n",
        "    #classWeights = torch.tensor([0.5, 1, 1, 1, 2], dtype=torch.float32).to(device)\n",
        "    classWeights = torch.tensor([0.55, 1.60, 1.21, 1.38], dtype=torch.float32).to(device)\n",
        "    loss = F.cross_entropy(predictEthnicity, targetEthnicity, weight=classWeights)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def lossFunction(predictAge, predictGender, predictEthnicity, targetAge, targetGender, targetEthnicity):\n",
        "    alpha = 1/50 # weight for age prediction\n",
        "    beta = 1/5 # weight for gender prediction\n",
        "    gamma = 2 # weight for ethncity prediction\n",
        "    ageLoss = lossAge(predictAge, targetAge)\n",
        "    genderLoss = lossGender(predictGender, targetGender)\n",
        "    ethnicityLoss = lossEthnicity(predictEthnicity, targetEthnicity)\n",
        "    totalLoss = alpha * ageLoss + beta * genderLoss + gamma * ethnicityLoss\n",
        "    return totalLoss, ageLoss, genderLoss, ethnicityLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VyGFkzdvZjsZ"
      },
      "outputs": [],
      "source": [
        "def trainNetwork(model, optimizer, lossFunction, trainLoader, validLoader, epochs, unfreezeEpoch, device, modelPath):\n",
        "    model.train()\n",
        "    trainLoaderSize = len(trainLoader)\n",
        "    validLoaderSize = len(validLoader)\n",
        "    for epoch in tqdm(range(1, epochs + 1)):\n",
        "        if epoch == unfreezeEpoch:\n",
        "            model.unfreeze()\n",
        "            print(\"\\tUnfreeze the model for fine tuning\")\n",
        "        \n",
        "        ### TRAINING ###\n",
        "        trainAgeLoss, trainGenderLoss, trainEthnicityLoss = 0, 0, 0\n",
        "        correctTrain = 0\n",
        "        totalTrain = 0\n",
        "        for batch_nr, (images, labels) in enumerate(trainLoader):\n",
        "            # Move data to GPU (if exists)\n",
        "            images, labels = images.to(device), labels.long().to(device) \n",
        "\n",
        "            ageLabels = labels[:, 0].view(-1, 1).float()\n",
        "            genderLabels = F.one_hot(labels[:, 1], num_classes=2).float()\n",
        "            #ethnicityLabels = F.one_hot(labels[:, 2], num_classes=5).float()\n",
        "            ethnicityLabels = F.one_hot(labels[:, 2], num_classes=4).float()\n",
        "\n",
        "            # Predict\n",
        "            agePredictions, genderPredictions, ethnicityPredictions = model(images)\n",
        "\n",
        "            # Get loss and backpropogate\n",
        "            totalLoss, ageLoss, genderLoss, ethnicityLoss = lossFunction(agePredictions, genderPredictions, ethnicityPredictions, \n",
        "                                                            ageLabels, genderLabels, ethnicityLabels)\n",
        "            \n",
        "            totalLoss.backward()\n",
        "\n",
        "            # Optimize parameters (weights and biases) and remove gradients after\n",
        "            optimizer.step() \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Save loss for whole epoch\n",
        "            trainAgeLoss += ageLoss.item()\n",
        "            trainGenderLoss += genderLoss.item()\n",
        "            trainEthnicityLoss += ethnicityLoss.item()\n",
        "            \n",
        "        trainAgeLoss /= trainLoaderSize\n",
        "        trainGenderLoss /= trainLoaderSize\n",
        "        trainEthnicityLoss /= trainLoaderSize\n",
        "        #trainAccuracy = 100 * correctTrain / totalTrain\n",
        "\n",
        "        ### VALIDATION ###\n",
        "        validAgeLoss, validGenderLoss, validEthnicityLoss = 0, 0, 0\n",
        "        correctValid = 0\n",
        "        totalValid = 0\n",
        "        for batch_nr, (images, labels) in enumerate(validLoader):\n",
        "            # Move data to GPU (if exists)\n",
        "            images, labels = images.to(device), labels.long().to(device) \n",
        "\n",
        "            ageLabels = labels[:, 0].view(-1, 1).float()\n",
        "            genderLabels = F.one_hot(labels[:, 1], num_classes=2).float()\n",
        "            #ethnicityLabels = F.one_hot(labels[:, 2], num_classes=5).float()\n",
        "            ethnicityLabels = F.one_hot(labels[:, 2], num_classes=4).float()\n",
        "\n",
        "            # Predict            \n",
        "            agePredictions, genderPredictions, ethnicityPredictions = model(images)\n",
        "\n",
        "            # Get loss\n",
        "            totalLoss, ageLoss, genderLoss, ethnicityLoss = lossFunction(agePredictions, genderPredictions, ethnicityPredictions, \n",
        "                                                            ageLabels, genderLabels, ethnicityLabels)\n",
        "            \n",
        "            # Save loss for whole epoch\n",
        "            validAgeLoss += ageLoss.item()\n",
        "            validGenderLoss += genderLoss.item()\n",
        "            validEthnicityLoss += ethnicityLoss.item()\n",
        "\n",
        "        validAgeLoss /= validLoaderSize\n",
        "        validGenderLoss /= validLoaderSize\n",
        "        validEthnicityLoss /= validLoaderSize\n",
        "        #validAccuracy = 100 * correctValid / totalValid\n",
        "\n",
        "        # Print reuslt of epoch\n",
        "        print(f'\\n\\tTraining Losses:   (Age: {trainAgeLoss:.4f}, Gender: {trainGenderLoss:.4f}, Ethnicity: {trainEthnicityLoss:.4f})\\t'\n",
        "              f'\\n\\tValidation Losses: (Age: {validAgeLoss:.4f}, Gender: {validGenderLoss:.4f}, Ethnicity: {validEthnicityLoss:.4f})\\t')\n",
        "        \n",
        "    torch.save(model, modelPath)\n",
        "    print(f\"Saved model to {modelPath}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shpRsm7hi3bg",
        "outputId": "3be65e71-c744-4ff1-ee44-dbab7d72a31e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 213MB/s]\n"
          ]
        }
      ],
      "source": [
        "resnetModel = ResNetModel().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 6\n",
        "unfreezeEpoch = 4\n",
        "learningRate = 2e-2\n",
        "modelPath = \"resnet18.pth\"\n",
        "\n",
        "optimizer = torch.optim.SGD(resnetModel.parameters(), lr=learningRate)\n",
        "\n",
        "trainNetwork(resnetModel, optimizer, lossFunction, trainLoader, validLoader, epochs, unfreezeEpoch, device, modelPath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "U8ODUZUoG0XB",
        "outputId": "26f5346d-dad6-4939-c8f8-e1a898d82b6c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/6 [25:55<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-92be41e99b86>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnetModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnetModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfreezeEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-e22990929fb2>\u001b[0m in \u001b[0;36mtrainNetwork\u001b[0;34m(model, optimizer, lossFunction, trainLoader, validLoader, epochs, unfreezeEpoch, device, modelPath)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0magePredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenderPredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0methnicityPredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Get loss and backpropogate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-f5ed751bf31b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mresOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mageX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mageHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresOut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mageOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mageFc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mageX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = torch.load(modelPath)\n",
        "#model.eval()"
      ],
      "metadata": {
        "id": "Qpx2_Tn3p9O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtfZSqAgzatB"
      },
      "outputs": [],
      "source": [
        "#for name, param in resnetModel.named_parameters():\n",
        "#    print(name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def testNetwork(model, testLoader, device):\n",
        "    model.eval()\n",
        "    correctAge3, correctAge5, correctGender, correctEthnicity = 0, 0, 0, 0\n",
        "    correctTest = 0\n",
        "    totalTest = 0\n",
        "\n",
        "    allAgePredictions = torch.tensor([], dtype=torch.float32).to(device)\n",
        "    allGenderPredictions = torch.tensor([], dtype=torch.long).to(device)\n",
        "    allEthnicityPredictions = torch.tensor([], dtype=torch.long).to(device)\n",
        "    allAgeLabels = torch.tensor([], dtype=torch.float32).to(device)\n",
        "    allGenderLabels = torch.tensor([], dtype=torch.long).to(device)\n",
        "    allEthnicityLabels = torch.tensor([], dtype=torch.long).to(device)\n",
        "\n",
        "    ### TESTING ###\n",
        "    with torch.no_grad(): \n",
        "        for batch_nr, (images, labels) in enumerate(testLoader):\n",
        "            # Move data to GPU (if exists)\n",
        "            images, labels = images.to(device), labels.to(device)  \n",
        "\n",
        "            ageLabels = labels[:, 0]\n",
        "            genderLabels = labels[:, 1]\n",
        "            ethnicityLabels = labels[:, 2]\n",
        "            \n",
        "            # Get predictions and get the amount of correct predicitons\n",
        "            agePredictions, genderPredictions, ethnicityPredictions = model(images)\n",
        "\n",
        "            agePredictions = torch.round(agePredictions).view(1, -1)\n",
        "            correctAge3 += ((agePredictions - ageLabels).abs() <= 3).sum().item()\n",
        "            correctAge5 += ((agePredictions - ageLabels).abs() <= 5).sum().item()\n",
        "\n",
        "            _, genderPredictions = torch.max(genderPredictions, 1) \n",
        "            correctGender += (genderPredictions == genderLabels).sum().item() \n",
        "\n",
        "            _, ethnicityPredictions = torch.max(ethnicityPredictions, 1) \n",
        "            correctEthnicity += (ethnicityPredictions == ethnicityLabels).sum().item() \n",
        "\n",
        "            totalTest += len(images)\n",
        "            \n",
        "            # concatenate the predictions and labels of each batch\n",
        "            allAgePredictions = torch.cat((allAgePredictions, agePredictions), dim=1)\n",
        "            allGenderPredictions = torch.cat((allGenderPredictions, genderPredictions), dim=0)\n",
        "            allEthnicityPredictions = torch.cat((allEthnicityPredictions, ethnicityPredictions), dim=0)\n",
        "            allAgeLabels = torch.cat((allAgeLabels, ageLabels), dim=0)\n",
        "            allGenderLabels = torch.cat((allGenderLabels, genderLabels), dim=0)\n",
        "            allEthnicityLabels = torch.cat((allEthnicityLabels, ethnicityLabels), dim=0)\n",
        "\n",
        "    age3Accuracy = 100 * correctAge3 / totalTest\n",
        "    age5Accuracy = 100 * correctAge5 / totalTest\n",
        "    genderAccuracy = 100 * correctGender / totalTest\n",
        "    ethnicityAccuracy = 100 * correctEthnicity / totalTest\n",
        "\n",
        "    print(f\"Test Accuracy: (Age +/-3 years: {age3Accuracy:.2f}%, Age +/-5 years: {age5Accuracy:.2f}%, Gender: {genderAccuracy:.2f}%, Ethnicity: {ethnicityAccuracy:.2f}%)\")\n",
        "    return allAgePredictions, allGenderPredictions, allEthnicityPredictions, allAgeLabels, allGenderLabels, allEthnicityLabels"
      ],
      "metadata": {
        "id": "fOMVxs4mdBOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agePredictions, genderPredictions, ethnicityPredictions, ageLabels, genderLabels, ethnicityLabels = testNetwork(resnetModel, validLoader, device)"
      ],
      "metadata": {
        "id": "v6xAG82Tittx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agePredictions, ageLabels"
      ],
      "metadata": {
        "id": "ADzgJrCqr5ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ethnicityPredictions, ethnicityLabels"
      ],
      "metadata": {
        "id": "GbaWa-tZkKRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "GENDER = ['M', 'F']\n",
        "#ETHNICITY = ['White', 'Black', 'Asian', 'Indian', 'Others']\n",
        "ETHNICITY = ['White', 'Black', 'Asian', 'Indian']\n",
        "import pandas as pd\n",
        "import sklearn.metrics as skmetric\n",
        "\n",
        "matrix = skmetric.confusion_matrix(ethnicityLabels.cpu(), ethnicityPredictions.cpu())\n",
        "display = skmetric.ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=ETHNICITY)\n",
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "display.plot(ax=ax)\n",
        "plt.show()\n",
        "\n",
        "#print(skmetric.classification_report(arrayEmotionNumToString(testEncodedEmotionLabel), arrayEmotionNumToString(predTestEncodedEmotionLabel)))"
      ],
      "metadata": {
        "id": "Pnkb-mJ5ijyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = skmetric.confusion_matrix(genderLabels.cpu(), genderPredictions.cpu())\n",
        "display = skmetric.ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=GENDER)\n",
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "display.plot(ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v19jlnciqNsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = agePredictions.cpu()[0]\n",
        "plt.scatter(y_test, ageLabels.cpu(), s=2)\n",
        "plt.plot([0, 130], [0, 130], 'k--', lw=2)\n",
        "plt.xlabel('Actual Age')\n",
        "plt.ylabel('Predicted Age')\n",
        "plt.title('Actual vs. Predicted Ages')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dvDYpfLH1Z8r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0e46589cfc653cddf5fb35f750697a95da7a749fba015bbad1355989ab2e8d35"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}