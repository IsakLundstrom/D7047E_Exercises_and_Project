{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "loqLueA6ZjsN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.cuda\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import requests, tarfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaGoxjrxZjsS",
        "outputId": "45d9f40c-bf07-4a2c-d98b-d715b63b3b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FddWCNRzZjsU",
        "outputId": "5ae35f02-39bd-4e46-dd8f-415dd555566c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UTKFace already downloaded.\n"
          ]
        }
      ],
      "source": [
        "dataPath = 'UTKFace'\n",
        "if (dataPath not in os.listdir()):\n",
        "    print(\"Downloading UTKFace...\")\n",
        "    url = \"https://drive.google.com/uc?export=download&id=0BxYys69jI14kYVM3aVhKS1VhRUk&confirm=t&uuid=f981ca1d-ba0f-40c9-a4a0-8eaa887f3b6d&at=ANzk5s7e36SgjT0FlqBbRiijefRg:1681897584880\"\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    file = tarfile.open(fileobj=response.raw, mode=\"r|gz\")\n",
        "    file.extractall(path=\".\")\n",
        "    print(\"Download complete.\")\n",
        "else:\n",
        "    print(\"UTKFace already downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p808DasNdMtZ"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataPath, transform=None):\n",
        "        self.dataPath = dataPath\n",
        "        self.transform = transform\n",
        "        #self.imagePaths = [f for f in os.listdir(self.dataPath) if f.endswith('.jpg')]\n",
        "        self.imagePaths = [f for f in os.listdir(self.dataPath) if f.endswith('.jpg') and f.split('_')[2] != '4']\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        imagePath = self.imagePaths[index]\n",
        "        try:\n",
        "            imageTensor = torchvision.io.read_image(f'{self.dataPath}/{imagePath}').float()\n",
        "            fileName = imagePath.split('_')\n",
        "            label = torch.Tensor([int(fileName[0]), int(fileName[1]), int(fileName[2])])\n",
        "            if self.transform:\n",
        "                imageTensor = self.transform(imageTensor)\n",
        "            return imageTensor, label\n",
        "        except:\n",
        "            return self.__getitem__((index + 1) % len(self.imagePaths))\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imagePaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFTvbBTeZjsX",
        "outputId": "cae181cd-804e-4ede-802a-80f966914261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22016 15411 4404 2201\n"
          ]
        }
      ],
      "source": [
        "# Resize and normalizde\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize(224, antialias=True),\n",
        "     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "dataset = MyDataset(dataPath, transform=transform)\n",
        "\n",
        "batchSize = 100\n",
        "testSplit = 0.1 # use 10% of dataset as test\n",
        "validSplit = 0.2 / (1-testSplit) # use 20% of dataset as validation\n",
        "\n",
        "testSize = int(np.floor(len(dataset)*testSplit))\n",
        "trainValidSize = len(dataset) - testSize\n",
        "validSize = int(np.ceil(trainValidSize*validSplit))\n",
        "trainSize = trainValidSize - validSize\n",
        "print(len(dataset), trainSize, validSize, testSize)\n",
        "\n",
        "trainValidSet, testSet = torch.utils.data.random_split(dataset, [trainValidSize, testSize])\n",
        "trainSet, validSet = torch.utils.data.random_split(trainValidSet, [trainSize, validSize])\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=batchSize, shuffle=True)\n",
        "validLoader = torch.utils.data.DataLoader(validSet, batch_size=batchSize, shuffle=True)\n",
        "testLoader = torch.utils.data.DataLoader(testSet, batch_size=batchSize, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rOCaZIQkZjsY"
      },
      "outputs": [],
      "source": [
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNetModel,self).__init__()\n",
        "        self.resnet = torchvision.models.resnet34(pretrained=True)\n",
        "        for param in self.resnet.parameters():\n",
        "            param.requires_grad=False\n",
        "        self.resnet.fc = nn.Linear(512, 512)\n",
        "        self.ageHidden = nn.Linear(512,512)\n",
        "        self.genderHidden = nn.Linear(512,512)\n",
        "        self.ethnicityHidden = nn.Linear(512,512)\n",
        "        self.ageFc = nn.Linear(512,1)\n",
        "        self.genderFc = nn.Linear(512,2)\n",
        "        #self.ethnicityFc = nn.Linear(512,5)\n",
        "        self.ethnicityFc = nn.Linear(512,4)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        resOut = F.relu(self.resnet.forward(x))\n",
        "        ageX = F.relu(self.ageHidden(resOut))\n",
        "        ageOut = self.ageFc(ageX)\n",
        "        genderX = F.relu(self.genderHidden(resOut))\n",
        "        genderOut = F.sigmoid(self.genderFc(genderX))\n",
        "        ethnicityX = F.relu(self.ethnicityHidden(resOut))\n",
        "        ethnicityOut = self.ethnicityFc(ethnicityX)\n",
        "        return ageOut, genderOut, ethnicityOut\n",
        "\n",
        "    def unfreeze(self):\n",
        "        for param in self.resnet.parameters():\n",
        "            param.requires_grad=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EyEWr79LZjsY"
      },
      "outputs": [],
      "source": [
        "# ResNetModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PPTkQJzyZjsY"
      },
      "outputs": [],
      "source": [
        "def lossAge(predictAge, targetAge):\n",
        "    #loss = torch.sqrt(F.mse_loss(predictAge, targetAge))\n",
        "    #return loss\n",
        "\n",
        "    # Define age ranges and corresponding weights\n",
        "    age_ranges = [(0, 1), (2, 23), (24, 25), (26, 26), (27, 35), (36, 150)]\n",
        "    age_weights = [0.4, 1, 0.6, 0.2, 0.6, 1.5]\n",
        "\n",
        "    # Compute the weighted age loss\n",
        "    loss_weights = torch.zeros_like(targetAge, dtype=torch.float32)\n",
        "    for i, (start, end) in enumerate(age_ranges):\n",
        "        mask = (targetAge >= start) & (targetAge <= end)\n",
        "        loss_weights[mask] = age_weights[i]\n",
        "    loss = torch.sqrt(F.mse_loss(predictAge, targetAge, reduction='none'))\n",
        "    weighted_loss = loss * loss_weights\n",
        "    return torch.mean(weighted_loss)\n",
        "\n",
        "def lossGender(predictGender, targetGender):\n",
        "    classWeights = torch.tensor([0.95, 1.06], dtype=torch.float32).to(device)\n",
        "    loss = F.binary_cross_entropy(predictGender, targetGender, weight=classWeights)\n",
        "    return loss\n",
        "\n",
        "def lossEthnicity(predictEthnicity, targetEthnicity):\n",
        "    #classWeights = torch.tensor([0.5, 1, 1, 1, 2], dtype=torch.float32).to(device)\n",
        "    #classWeights = torch.tensor([0.55, 1.60, 1.21, 1.38], dtype=torch.float32).to(device)\n",
        "    classWeights = torch.tensor([0.55, 1.60, 1.21, 1.38], dtype=torch.float32).to(device)\n",
        "    loss = F.cross_entropy(predictEthnicity, targetEthnicity, weight=classWeights)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def lossFunction(predictAge, predictGender, predictEthnicity, targetAge, targetGender, targetEthnicity):\n",
        "    alpha = 1/20 # weight for age prediction\n",
        "    beta = 3/5 # weight for gender prediction\n",
        "    gamma = 4/5 # weight for ethncity prediction\n",
        "    alpha = 1/9 # weight for age prediction\n",
        "    beta = 3/5 # weight for gender prediction\n",
        "    gamma = 1 # weight for ethncity prediction\n",
        "    ageLoss = lossAge(predictAge, targetAge)\n",
        "    genderLoss = lossGender(predictGender, targetGender)\n",
        "    ethnicityLoss = lossEthnicity(predictEthnicity, targetEthnicity)\n",
        "    totalLoss = alpha * ageLoss + beta * genderLoss + gamma * ethnicityLoss\n",
        "    return totalLoss, ageLoss, genderLoss, ethnicityLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VyGFkzdvZjsZ"
      },
      "outputs": [],
      "source": [
        "def trainNetwork(model, optimizer, lossFunction, trainLoader, validLoader, epochs, unfreezeEpoch, device, modelPath):\n",
        "    model.train()\n",
        "    trainLoaderSize = len(trainLoader)\n",
        "    validLoaderSize = len(validLoader)\n",
        "    trainAgeLoss, trainGenderLoss, trainEthnicityLoss, trainTotalLoss = [], [], [], []\n",
        "    validAgeLoss, validGenderLoss, validEthnicityLoss, validTotalLoss = [], [], [], []\n",
        "    trainAge3Accuracy, trainAge5Accuracy, trainGenderAccuracy, trainEthnicityAccuracy = [], [], [], []\n",
        "    validAge3Accuracy, validAge5Accuracy, validGenderAccuracy, validEthnicityAccuracy = [], [], [], []\n",
        "\n",
        "    for epoch in tqdm(range(1, epochs + 1)):\n",
        "        if epoch == unfreezeEpoch:\n",
        "            model.unfreeze()\n",
        "            print(\"\\tUnfreeze the model for fine tuning\")\n",
        "        \n",
        "        ### TRAINING ###\n",
        "        trainAgeLoss.append(0)\n",
        "        trainGenderLoss.append(0)\n",
        "        trainEthnicityLoss.append(0)\n",
        "        trainTotalLoss.append(0)\n",
        "        trainAge3Accuracy.append(0)\n",
        "        trainAge5Accuracy.append(0)\n",
        "        trainGenderAccuracy.append(0)\n",
        "        trainEthnicityAccuracy.append(0)\n",
        "\n",
        "        for batch_nr, (images, labels) in enumerate(trainLoader):\n",
        "            # Move data to GPU (if exists)\n",
        "            images, labels = images.to(device), labels.long().to(device) \n",
        "\n",
        "            ageLabels = labels[:, 0]\n",
        "            genderLabels = labels[:, 1]\n",
        "            #ethnicityLabels = F.one_hot(labels[:, 2], num_classes=5).float()\n",
        "            ethnicityLabels = labels[:, 2]\n",
        "\n",
        "            # Predict\n",
        "            agePredictions, genderPredictions, ethnicityPredictions = model(images)\n",
        "\n",
        "            # Get loss and backpropogate\n",
        "            totalLoss, ageLoss, genderLoss, ethnicityLoss = lossFunction(agePredictions, genderPredictions, ethnicityPredictions, \n",
        "                                                            ageLabels.view(-1, 1).float(), F.one_hot(genderLabels, num_classes=2).float(), F.one_hot(ethnicityLabels, num_classes=4).float())\n",
        "            \n",
        "            totalLoss.backward()\n",
        "\n",
        "            # Optimize parameters (weights and biases) and remove gradients after\n",
        "            optimizer.step() \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Save loss for whole epoch\n",
        "            trainAgeLoss[-1] += ageLoss.item() / trainLoaderSize\n",
        "            trainGenderLoss[-1] += genderLoss.item() / trainLoaderSize\n",
        "            trainEthnicityLoss[-1] += ethnicityLoss.item() / trainLoaderSize\n",
        "            trainTotalLoss[-1] += ethnicityLoss.item() / trainLoaderSize\n",
        "\n",
        "            # Calcualte accuracy\n",
        "            totalTrain = len(images) * trainLoaderSize\n",
        "            \n",
        "            agePredictions = torch.round(agePredictions).view(1, -1)\n",
        "            trainAge3Accuracy[-1] += ((agePredictions - ageLabels).abs() <= 3).sum().item() * 100 / totalTrain\n",
        "            trainAge5Accuracy[-1] += ((agePredictions - ageLabels).abs() <= 5).sum().item() * 100 / totalTrain\n",
        "\n",
        "            _, genderPredictions = torch.max(genderPredictions, 1) \n",
        "            trainGenderAccuracy[-1] += (genderPredictions == genderLabels).sum().item() * 100 / totalTrain\n",
        "\n",
        "            _, ethnicityPredictions = torch.max(ethnicityPredictions, 1) \n",
        "            trainEthnicityAccuracy[-1] += (ethnicityPredictions == ethnicityLabels).sum().item() * 100 / totalTrain\n",
        "\n",
        "        ### VALIDATION ###\n",
        "        validAgeLoss.append(0)\n",
        "        validGenderLoss.append(0)\n",
        "        validEthnicityLoss.append(0)\n",
        "        validTotalLoss.append(0)\n",
        "        validAge3Accuracy.append(0)\n",
        "        validAge5Accuracy.append(0)\n",
        "        validGenderAccuracy.append(0)\n",
        "        validEthnicityAccuracy.append(0)\n",
        "\n",
        "        for batch_nr, (images, labels) in enumerate(validLoader):\n",
        "            # Move data to GPU (if exists)\n",
        "            images, labels = images.to(device), labels.long().to(device) \n",
        "\n",
        "            ageLabels = labels[:, 0]\n",
        "            genderLabels = labels[:, 1]\n",
        "            #ethnicityLabels = F.one_hot(labels[:, 2], num_classes=5).float()\n",
        "            ethnicityLabels = labels[:, 2]\n",
        "\n",
        "            # Predict            \n",
        "            agePredictions, genderPredictions, ethnicityPredictions = model(images)\n",
        "\n",
        "            # Get loss\n",
        "            totalLoss, ageLoss, genderLoss, ethnicityLoss = lossFunction(agePredictions, genderPredictions, ethnicityPredictions, \n",
        "                                                            ageLabels.view(-1, 1).float(), F.one_hot(genderLabels, num_classes=2).float(), F.one_hot(ethnicityLabels, num_classes=4).float())\n",
        "            \n",
        "            # Save loss for whole epoch\n",
        "            validAgeLoss[-1] += ageLoss.item() / validLoaderSize\n",
        "            validGenderLoss[-1] += genderLoss.item() / validLoaderSize\n",
        "            validEthnicityLoss[-1] += ethnicityLoss.item() / validLoaderSize\n",
        "            validTotalLoss[-1] += ethnicityLoss.item() / validLoaderSize\n",
        "\n",
        "            # Calcualte accuracy\n",
        "            totalValid = len(images) * validLoaderSize\n",
        "\n",
        "            agePredictions = torch.round(agePredictions).view(1, -1)\n",
        "            validAge3Accuracy[-1] += ((agePredictions - ageLabels).abs() <= 3).sum().item() * 100 / totalValid\n",
        "            validAge5Accuracy[-1] += ((agePredictions - ageLabels).abs() <= 5).sum().item() * 100 / totalValid\n",
        "            \n",
        "            _, genderPredictions = torch.max(genderPredictions, 1) \n",
        "            validGenderAccuracy[-1] += (genderPredictions == genderLabels).sum().item() * 100 / totalValid\n",
        "\n",
        "            _, ethnicityPredictions = torch.max(ethnicityPredictions, 1) \n",
        "            validEthnicityAccuracy[-1] += (ethnicityPredictions == ethnicityLabels).sum().item() * 100 / totalValid\n",
        "\n",
        "\n",
        "        # Print reuslt of epoch\n",
        "        print(f'\\n\\tTraining Losses:     (Age: {trainAgeLoss[-1]:.3f}, Gender: {trainGenderLoss[-1]:.3f}, Ethnicity: {trainEthnicityLoss[-1]:.3f}, Total: {trainTotalLoss[-1]:.3f})\\t'\n",
        "              f'\\n\\tValidation Losses:   (Age: {validAgeLoss[-1]:.3f}, Gender: {validGenderLoss[-1]:.3f}, Ethnicity: {validEthnicityLoss[-1]:.3f}, Total: {validTotalLoss[-1]:.3f})\\t'\n",
        "              f'\\n\\tTraining Accuracy:   (Age+/-3: {trainAge3Accuracy[-1]:.2f}%, Age+/-5: {trainAge5Accuracy[-1]:.2f}%, Gender: {trainGenderAccuracy[-1]:.2f}%, Ethnicity: {trainEthnicityAccuracy[-1]:.2f}%)\\t'\n",
        "              f'\\n\\tValidation Accuracy: (Age+/-3: {validAge3Accuracy[-1]:.2f}%, Age+/-5: {validAge5Accuracy[-1]:.2f}%, Gender: {validGenderAccuracy[-1]:.2f}%, Ethnicity: {validEthnicityAccuracy[-1]:.2f}%)\\t')\n",
        "        \n",
        "    torch.save(model, modelPath)\n",
        "    print(f\"Saved model to {modelPath}\")\n",
        "    losses = [trainAgeLoss, trainGenderLoss, trainEthnicityLoss, trainTotalLoss, validAgeLoss, validGenderLoss, validEthnicityLoss, validTotalLoss]\n",
        "    accuracy = [trainAge3Accuracy, trainAge5Accuracy, trainGenderAccuracy, trainEthnicityAccuracy, validAge3Accuracy, validAge5Accuracy, validGenderAccuracy, validEthnicityAccuracy]\n",
        "    return losses, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "shpRsm7hi3bg"
      },
      "outputs": [],
      "source": [
        "resnetModel = ResNetModel().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "unfreezeEpoch = 3\n",
        "learningRate = 5e-3\n",
        "modelPath = \"resnet.pth\"\n",
        "\n",
        "optimizer = torch.optim.SGD(resnetModel.parameters(), lr=learningRate, weight_decay=0.05)\n",
        "\n",
        "losses, accuracy = trainNetwork(resnetModel, optimizer, lossFunction, trainLoader, validLoader, epochs, unfreezeEpoch, device, modelPath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "U8ODUZUoG0XB",
        "outputId": "542e1fa5-0b1c-4999-fa39-d072f1ffbce0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [01:16<11:24, 76.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tTraining Losses:     (Age: 23.475, Gender: 0.684, Ethnicity: 1.335, Total: 1.335)\t\n",
            "\tValidation Losses:   (Age: 15.521, Gender: 0.671, Ethnicity: 1.320, Total: 1.320)\t\n",
            "\tTraining Accuracy:   (Age+/-3: 10.54%, Age+/-5: 16.09%, Gender: 56.89%, Ethnicity: 29.64%)\t\n",
            "\tValidation Accuracy: (Age+/-3: 8.91%, Age+/-5: 14.71%, Gender: 62.40%, Ethnicity: 49.84%)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [02:27<09:48, 73.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tTraining Losses:     (Age: 14.800, Gender: 0.648, Ethnicity: 1.175, Total: 1.175)\t\n",
            "\tValidation Losses:   (Age: 13.238, Gender: 0.627, Ethnicity: 1.101, Total: 1.101)\t\n",
            "\tTraining Accuracy:   (Age+/-3: 14.41%, Age+/-5: 22.77%, Gender: 65.56%, Ethnicity: 52.28%)\t\n",
            "\tValidation Accuracy: (Age+/-3: 15.22%, Age+/-5: 24.56%, Gender: 69.84%, Ethnicity: 55.42%)\t\n",
            "\tUnfreeze the model for fine tuning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [04:27<11:02, 94.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tTraining Losses:     (Age: 8.670, Gender: 0.583, Ethnicity: 0.834, Total: 0.834)\t\n",
            "\tValidation Losses:   (Age: 8.144, Gender: 0.514, Ethnicity: 0.675, Total: 0.675)\t\n",
            "\tTraining Accuracy:   (Age+/-3: 29.38%, Age+/-5: 43.38%, Gender: 73.33%, Ethnicity: 67.33%)\t\n",
            "\tValidation Accuracy: (Age+/-3: 31.24%, Age+/-5: 44.33%, Gender: 78.16%, Ethnicity: 78.11%)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [06:33<10:41, 106.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tTraining Losses:     (Age: 6.440, Gender: 0.412, Ethnicity: 0.518, Total: 0.518)\t\n",
            "\tValidation Losses:   (Age: 10.807, Gender: 0.330, Ethnicity: 0.523, Total: 0.523)\t\n",
            "\tTraining Accuracy:   (Age+/-3: 39.90%, Age+/-5: 56.36%, Gender: 82.57%, Ethnicity: 81.74%)\t\n",
            "\tValidation Accuracy: (Age+/-3: 20.60%, Age+/-5: 30.40%, Gender: 86.40%, Ethnicity: 83.44%)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [08:37<12:55, 129.26s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-dc8e57f84e98>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnetModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnetModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfreezeEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-bb92dcf3740d>\u001b[0m in \u001b[0;36mtrainNetwork\u001b[0;34m(model, optimizer, lossFunction, trainLoader, validLoader, epochs, unfreezeEpoch, device, modelPath)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;31m# Get loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             totalLoss, ageLoss, genderLoss, ethnicityLoss = lossFunction(agePredictions, genderPredictions, ethnicityPredictions, \n\u001b[0m\u001b[1;32m     90\u001b[0m                                                             ageLabels.view(-1, 1).float(), F.one_hot(genderLabels, num_classes=2).float(), F.one_hot(ethnicityLabels, num_classes=4).float())\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-124b8a7213aa>\u001b[0m in \u001b[0;36mlossFunction\u001b[0;34m(predictAge, predictGender, predictEthnicity, targetAge, targetGender, targetEthnicity)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# weight for ethncity prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mageLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossAge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictAge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetAge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mgenderLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossGender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictGender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetGender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0methnicityLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossEthnicity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictEthnicity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetEthnicity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtotalLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mageLoss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgenderLoss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0methnicityLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-124b8a7213aa>\u001b[0m in \u001b[0;36mlossGender\u001b[0;34m(predictGender, targetGender)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlossGender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictGender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetGender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mclassWeights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.06\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictGender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetGender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassWeights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plotLossesAccuracy(losses, accuracy):\n",
        "    fig, axs = plt.subplots(2, 4, figsize=(12, 7))\n",
        "\n",
        "    # age loss\n",
        "    axs[0, 0].plot(losses[0], label='Train')\n",
        "    axs[0, 0].plot(losses[4], label='Validation')\n",
        "    axs[0, 0].set_title('Age Loss')\n",
        "    axs[0, 0].legend()\n",
        "\n",
        "    # gender loss\n",
        "    axs[0, 1].plot(losses[1], label='Train')\n",
        "    axs[0, 1].plot(losses[5], label='Validation')\n",
        "    axs[0, 1].set_title('Gender Loss')\n",
        "    axs[0, 1].legend()\n",
        "\n",
        "    # ethnicity loss\n",
        "    axs[0, 2].plot(losses[2], label='Train')\n",
        "    axs[0, 2].plot(losses[6], label='Validation')\n",
        "    axs[0, 2].set_title('Ethnicity Loss')\n",
        "    axs[0, 2].legend()\n",
        "\n",
        "    # total loss\n",
        "    axs[0, 3].plot(losses[3], label='Train')\n",
        "    axs[0, 3].plot(losses[7], label='Validation')\n",
        "    axs[0, 3].set_title('Total Loss')\n",
        "    axs[0, 3].legend()\n",
        "\n",
        "    # age accuracies\n",
        "    axs[1, 0].plot(accuracy[0], label='Train +/-3')\n",
        "    axs[1, 0].plot(accuracy[4], label='Validation +/-3')\n",
        "    axs[1, 0].plot(accuracy[1], '--', label='Train +/-5')\n",
        "    axs[1, 0].plot(accuracy[5], '--', label='Validation +/-5')\n",
        "    axs[1, 0].set_title('Age Accuracy')\n",
        "    axs[1, 0].legend()\n",
        "\n",
        "    # gender accuracy\n",
        "    axs[1, 1].plot(accuracy[2], label='Train')\n",
        "    axs[1, 1].plot(accuracy[6], label='Validation')\n",
        "    axs[1, 1].set_title('Gender Accuracy')\n",
        "    axs[1, 1].legend()\n",
        "\n",
        "    # ethnicity accuracy\n",
        "    axs[1, 2].plot(accuracy[3], label='Train')\n",
        "    axs[1, 2].plot(accuracy[7], label='Validation')\n",
        "    axs[1, 2].set_title('Ethnicity Accuracy')\n",
        "    axs[1, 2].legend()\n",
        "\n",
        "    axs[1, 3].set_visible(False)\n",
        "\n",
        "    # title and adjust the spacing\n",
        "    fig.suptitle('Losses and Accuracy')\n",
        "    fig.tight_layout()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vrqxuwhCHcdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotLossesAccuracy(losses, accuracy)"
      ],
      "metadata": {
        "id": "e9lQHYI_H4u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = torch.load(modelPath)\n",
        "#model.eval()"
      ],
      "metadata": {
        "id": "Qpx2_Tn3p9O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtfZSqAgzatB"
      },
      "outputs": [],
      "source": [
        "#for name, param in resnetModel.named_parameters():\n",
        "#    print(name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def testNetwork(model, testLoader, device):\n",
        "    model.eval()\n",
        "    correctAge3, correctAge5, correctGender, correctEthnicity = 0, 0, 0, 0\n",
        "    correctTest = 0\n",
        "    totalTest = 0\n",
        "\n",
        "    allAgePredictions = torch.tensor([], dtype=torch.float32).to(device)\n",
        "    allGenderPredictions = torch.tensor([], dtype=torch.long).to(device)\n",
        "    allEthnicityPredictions = torch.tensor([], dtype=torch.long).to(device)\n",
        "    allAgeLabels = torch.tensor([], dtype=torch.float32).to(device)\n",
        "    allGenderLabels = torch.tensor([], dtype=torch.long).to(device)\n",
        "    allEthnicityLabels = torch.tensor([], dtype=torch.long).to(device)\n",
        "\n",
        "    ### TESTING ###\n",
        "    with torch.no_grad(): \n",
        "        for batch_nr, (images, labels) in enumerate(testLoader):\n",
        "            # Move data to GPU (if exists)\n",
        "            images, labels = images.to(device), labels.to(device)  \n",
        "\n",
        "            ageLabels = labels[:, 0]\n",
        "            genderLabels = labels[:, 1]\n",
        "            ethnicityLabels = labels[:, 2]\n",
        "            \n",
        "            # Get predictions and get the amount of correct predicitons\n",
        "            agePredictions, genderPredictions, ethnicityPredictions = model(images)\n",
        "\n",
        "            agePredictions = torch.round(agePredictions).view(1, -1)\n",
        "            correctAge3 += ((agePredictions - ageLabels).abs() <= 3).sum().item()\n",
        "            correctAge5 += ((agePredictions - ageLabels).abs() <= 5).sum().item()\n",
        "\n",
        "            _, genderPredictions = torch.max(genderPredictions, 1) \n",
        "            correctGender += (genderPredictions == genderLabels).sum().item() \n",
        "\n",
        "            _, ethnicityPredictions = torch.max(ethnicityPredictions, 1) \n",
        "            correctEthnicity += (ethnicityPredictions == ethnicityLabels).sum().item() \n",
        "\n",
        "            totalTest += len(images)\n",
        "            \n",
        "            # concatenate the predictions and labels of each batch\n",
        "            allAgePredictions = torch.cat((allAgePredictions, agePredictions), dim=1)\n",
        "            allGenderPredictions = torch.cat((allGenderPredictions, genderPredictions), dim=0)\n",
        "            allEthnicityPredictions = torch.cat((allEthnicityPredictions, ethnicityPredictions), dim=0)\n",
        "            allAgeLabels = torch.cat((allAgeLabels, ageLabels), dim=0)\n",
        "            allGenderLabels = torch.cat((allGenderLabels, genderLabels), dim=0)\n",
        "            allEthnicityLabels = torch.cat((allEthnicityLabels, ethnicityLabels), dim=0)\n",
        "\n",
        "    age3Accuracy = 100 * correctAge3 / totalTest\n",
        "    age5Accuracy = 100 * correctAge5 / totalTest\n",
        "    genderAccuracy = 100 * correctGender / totalTest\n",
        "    ethnicityAccuracy = 100 * correctEthnicity / totalTest\n",
        "\n",
        "    print(f\"Test Accuracy: (Age +/-3 years: {age3Accuracy:.2f}%, Age +/-5 years: {age5Accuracy:.2f}%, Gender: {genderAccuracy:.2f}%, Ethnicity: {ethnicityAccuracy:.2f}%)\")\n",
        "    return allAgePredictions, allGenderPredictions, allEthnicityPredictions, allAgeLabels, allGenderLabels, allEthnicityLabels"
      ],
      "metadata": {
        "id": "fOMVxs4mdBOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agePredictions, genderPredictions, ethnicityPredictions, ageLabels, genderLabels, ethnicityLabels = testNetwork(resnetModel, validLoader, device)"
      ],
      "metadata": {
        "id": "v6xAG82Tittx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agePredictions, ageLabels"
      ],
      "metadata": {
        "id": "ADzgJrCqr5ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ethnicityPredictions, ethnicityLabels"
      ],
      "metadata": {
        "id": "GbaWa-tZkKRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "GENDER = ['M', 'F']\n",
        "#ETHNICITY = ['White', 'Black', 'Asian', 'Indian', 'Others']\n",
        "ETHNICITY = ['White', 'Black', 'Asian', 'Indian']\n",
        "import pandas as pd\n",
        "import sklearn.metrics as skmetric\n",
        "\n",
        "matrix = skmetric.confusion_matrix(ethnicityLabels.cpu(), ethnicityPredictions.cpu())\n",
        "display = skmetric.ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=ETHNICITY)\n",
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "display.plot(ax=ax)\n",
        "plt.show()\n",
        "\n",
        "#print(skmetric.classification_report(arrayEmotionNumToString(testEncodedEmotionLabel), arrayEmotionNumToString(predTestEncodedEmotionLabel)))"
      ],
      "metadata": {
        "id": "Pnkb-mJ5ijyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = skmetric.confusion_matrix(genderLabels.cpu(), genderPredictions.cpu())\n",
        "display = skmetric.ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=GENDER)\n",
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "display.plot(ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v19jlnciqNsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(agePredictions.cpu()[0], ageLabels.cpu(), s=2)\n",
        "plt.plot([0, 120], [0, 120], 'k--', lw=2)\n",
        "plt.xlabel('Actual Age')\n",
        "plt.ylabel('Predicted Age')\n",
        "plt.title('Actual vs. Predicted Ages')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dvDYpfLH1Z8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(ageLabels.cpu()), min(ageLabels.cpu())"
      ],
      "metadata": {
        "id": "O3rw23NOaQO2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0e46589cfc653cddf5fb35f750697a95da7a749fba015bbad1355989ab2e8d35"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}