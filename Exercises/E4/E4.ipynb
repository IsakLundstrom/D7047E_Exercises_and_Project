{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import *\n",
    "from model import *\n",
    "from generate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.filename = 'filename'\n",
    "        self.model = \"gru\"\n",
    "        self.n_epochs = 2000\n",
    "        self.print_every = 100\n",
    "        self.hidden_size = 100\n",
    "        self.n_layers = 2\n",
    "        self.learning_rate = 0.01\n",
    "        self.chunk_len = 200\n",
    "        self.batch_size = 100\n",
    "        self.shuffle = True\n",
    "        self.cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2000 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:13<1:48:28,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving before quit...\n",
      "Saved as shakespeare.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parse command line arguments\n",
    "# argparser = argparse.ArgumentParser()\n",
    "# argparser.add_argument('filename', type=str)\n",
    "# argparser.add_argument('--model', type=str, default=\"gru\")\n",
    "# argparser.add_argument('--n_epochs', type=int, default=2000)\n",
    "# argparser.add_argument('--print_every', type=int, default=100)\n",
    "# argparser.add_argument('--hidden_size', type=int, default=100)\n",
    "# argparser.add_argument('--n_layers', type=int, default=2)\n",
    "# argparser.add_argument('--learning_rate', type=float, default=0.01)\n",
    "# argparser.add_argument('--chunk_len', type=int, default=200)\n",
    "# argparser.add_argument('--batch_size', type=int, default=100)\n",
    "# argparser.add_argument('--shuffle', action='store_true')\n",
    "# argparser.add_argument('--cuda', action='store_true')\n",
    "# args = argparser.parse_args()\n",
    "\n",
    "args = Args()\n",
    "args.filename = 'shakespeare.txt'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    args.cuda = True\n",
    "\n",
    "if args.cuda:\n",
    "    print(\"Using CUDA\")\n",
    "\n",
    "file, file_len = read_file(args.filename)\n",
    "\n",
    "def random_training_set(chunk_len, batch_size):\n",
    "    inp = torch.LongTensor(batch_size, chunk_len)\n",
    "    target = torch.LongTensor(batch_size, chunk_len)\n",
    "    for bi in range(batch_size):\n",
    "        start_index = random.randint(0, file_len - chunk_len)\n",
    "        end_index = start_index + chunk_len + 1\n",
    "        chunk = file[start_index:end_index]\n",
    "        inp[bi] = char_tensor(chunk[:-1])\n",
    "        target[bi] = char_tensor(chunk[1:])\n",
    "    inp = Variable(inp)\n",
    "    target = Variable(target)\n",
    "    if args.cuda:\n",
    "        inp = inp.cuda()\n",
    "        target = target.cuda()\n",
    "    return inp, target\n",
    "\n",
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden(args.batch_size)\n",
    "    if args.cuda:\n",
    "        hidden = hidden.cuda()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(args.chunk_len):\n",
    "        output, hidden = decoder(inp[:,c], hidden)\n",
    "        loss += criterion(output.view(args.batch_size, -1), target[:,c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "    # print(\"test: \", loss.item())\n",
    "\n",
    "    return loss.item() / args.chunk_len\n",
    "\n",
    "def save():\n",
    "    save_filename = os.path.splitext(os.path.basename(args.filename))[0] + '.pt'\n",
    "    torch.save(decoder, save_filename)\n",
    "    print('Saved as %s' % save_filename)\n",
    "\n",
    "# Initialize models and start training\n",
    "\n",
    "decoder = CharRNN(\n",
    "    n_characters,\n",
    "    args.hidden_size,\n",
    "    n_characters,\n",
    "    model=args.model,\n",
    "    n_layers=args.n_layers,\n",
    ")\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=args.learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if args.cuda:\n",
    "    decoder.cuda()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "try:\n",
    "    print(\"Training for %d epochs...\" % args.n_epochs)\n",
    "    for epoch in tqdm(range(1, args.n_epochs + 1)):\n",
    "        loss = train(*random_training_set(args.chunk_len, args.batch_size))\n",
    "        loss_avg += loss\n",
    "\n",
    "        if epoch % args.print_every == 0:\n",
    "            print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / args.n_epochs * 100, loss))\n",
    "            print(generate(decoder, 'Wh', 100, cuda=args.cuda), '\\n')\n",
    "\n",
    "    print(\"Saving...\")\n",
    "    save()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Saving before quit...\")\n",
    "    save()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
