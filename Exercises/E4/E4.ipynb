{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import os\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import *\n",
    "from model import *\n",
    "from generate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.filename = 'filename'\n",
    "        self.model = \"gru\"\n",
    "        self.n_epochs = 2000\n",
    "        self.print_every = 100\n",
    "        self.hidden_size = 100\n",
    "        self.n_layers = 2\n",
    "        self.learning_rate = 0.01\n",
    "        self.chunk_len = 200\n",
    "        self.batch_size = 100\n",
    "        self.shuffle = True\n",
    "        self.cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, model=\"gru\", n_layers=1):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.model = model.lower()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        if self.model == \"gru\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        elif self.model == \"lstm\":\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size(0)\n",
    "        encoded = self.encoder(input)\n",
    "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def forward2(self, input, hidden):\n",
    "        encoded = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.rnn(encoded.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.model == \"lstm\":\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2000 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:13<1:48:28,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving before quit...\n",
      "Saved as shakespeare.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "args.filename = 'shakespeare.txt'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    args.cuda = True\n",
    "\n",
    "if args.cuda:\n",
    "    print(\"Using CUDA\")\n",
    "\n",
    "file, file_len = read_file(args.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and un-unicode-encoding data\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "def read_file(filename):\n",
    "    file = unidecode.unidecode(open(filename).read())\n",
    "    return file, len(file)\n",
    "\n",
    "# Turning a string into a tensor\n",
    "\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        try:\n",
    "            tensor[c] = all_characters.index(string[c])\n",
    "        except:\n",
    "            continue\n",
    "    return tensor\n",
    "\n",
    "# Readable time elapsed\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8, cuda=False):\n",
    "    hidden = decoder.init_hidden(1)\n",
    "    prime_input = Variable(char_tensor(prime_str).unsqueeze(0))\n",
    "\n",
    "    if cuda:\n",
    "        hidden = hidden.cuda()\n",
    "        prime_input = prime_input.cuda()\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[:,p], hidden)\n",
    "        \n",
    "    inp = prime_input[:,-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = Variable(char_tensor(predicted_char).unsqueeze(0))\n",
    "        if cuda:\n",
    "            inp = inp.cuda()\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_training_set(chunk_len, batch_size):\n",
    "    inp = torch.LongTensor(batch_size, chunk_len)\n",
    "    target = torch.LongTensor(batch_size, chunk_len)\n",
    "    for bi in range(batch_size):\n",
    "        start_index = random.randint(0, file_len - chunk_len)\n",
    "        end_index = start_index + chunk_len + 1\n",
    "        chunk = file[start_index:end_index]\n",
    "        inp[bi] = char_tensor(chunk[:-1])\n",
    "        target[bi] = char_tensor(chunk[1:])\n",
    "    inp = Variable(inp)\n",
    "    target = Variable(target)\n",
    "    if args.cuda:\n",
    "        inp = inp.cuda()\n",
    "        target = target.cuda()\n",
    "    return inp, target\n",
    "\n",
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden(args.batch_size)\n",
    "    if args.cuda:\n",
    "        hidden = hidden.cuda()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(args.chunk_len):\n",
    "        output, hidden = decoder(inp[:,c], hidden)\n",
    "        loss += criterion(output.view(args.batch_size, -1), target[:,c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "    # print(\"test: \", loss.item())\n",
    "\n",
    "    return loss.item() / args.chunk_len\n",
    "\n",
    "def save():\n",
    "    save_filename = os.path.splitext(os.path.basename(args.filename))[0] + '.pt'\n",
    "    torch.save(decoder, save_filename)\n",
    "    print('Saved as %s' % save_filename)\n",
    "\n",
    "# Initialize models and start training\n",
    "\n",
    "decoder = CharRNN(\n",
    "    n_characters,\n",
    "    args.hidden_size,\n",
    "    n_characters,\n",
    "    model=args.model,\n",
    "    n_layers=args.n_layers,\n",
    ")\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=args.learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if args.cuda:\n",
    "    decoder.cuda()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "try:\n",
    "    print(\"Training for %d epochs...\" % args.n_epochs)\n",
    "    for epoch in tqdm(range(1, args.n_epochs + 1)):\n",
    "        loss = train(*random_training_set(args.chunk_len, args.batch_size))\n",
    "        loss_avg += loss\n",
    "\n",
    "        if epoch % args.print_every == 0:\n",
    "            print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / args.n_epochs * 100, loss))\n",
    "            print(generate(decoder, 'Wh', 100, cuda=args.cuda), '\\n')\n",
    "\n",
    "    print(\"Saving...\")\n",
    "    save()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Saving before quit...\")\n",
    "    save()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
