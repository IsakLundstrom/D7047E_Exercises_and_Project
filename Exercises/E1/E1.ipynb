{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load and normalizde the data\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batchSize = 5\n",
    "validSize = 0.2 # use 20% of train set as validation\n",
    "\n",
    "trainValidSet = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testSet = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainSet, validSet = torch.utils.data.random_split(trainValidSet, [int(len(trainValidSet)*(1-validSize)), int(len(trainValidSet)*validSize)])\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=batchSize, shuffle=True)\n",
    "validLoader = torch.utils.data.DataLoader(validSet, batch_size=batchSize, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(testSet, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "to_onehot = nn.Embedding(len(classes), len(classes))\n",
    "to_onehot.weight.data = torch.eye(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2000, 2000, torch.Size([3, 32, 32]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainLoader), len(validLoader), len(testLoader), next(iter(testLoader))[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network class\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.0001\n",
    "\n",
    "network = ConvNet()\n",
    "\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate)\n",
    "lossFunction = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m loss\u001b[39m.\u001b[39mbackward() \n\u001b[0;32m     24\u001b[0m \u001b[39m# Optimize parameters (weights and biases) and remove gradients after\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep() \n\u001b[0;32m     26\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     28\u001b[0m \u001b[39m# Save loss for whole epoch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\isakl\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\isakl\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\torch\\autograd\\grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     27\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[1;32m---> 28\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\isakl\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\torch\\optim\\sgd.py:136\u001b[0m, in \u001b[0;36mSGD.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m             momentum_buffer_list\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmomentum_buffer\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 136\u001b[0m F\u001b[39m.\u001b[39;49msgd(params_with_grad,\n\u001b[0;32m    137\u001b[0m       d_p_list,\n\u001b[0;32m    138\u001b[0m       momentum_buffer_list,\n\u001b[0;32m    139\u001b[0m       weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    140\u001b[0m       momentum\u001b[39m=\u001b[39;49mmomentum,\n\u001b[0;32m    141\u001b[0m       lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    142\u001b[0m       dampening\u001b[39m=\u001b[39;49mdampening,\n\u001b[0;32m    143\u001b[0m       nesterov\u001b[39m=\u001b[39;49mnesterov)\n\u001b[0;32m    145\u001b[0m \u001b[39m# update momentum_buffers in state\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39mfor\u001b[39;00m p, momentum_buffer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[1;32mc:\\Users\\isakl\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\torch\\optim\\_functional.py:180\u001b[0m, in \u001b[0;36msgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m         d_p \u001b[39m=\u001b[39m buf\n\u001b[1;32m--> 180\u001b[0m param\u001b[39m.\u001b[39;49madd_(d_p, alpha\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mlr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "trainLossList = []\n",
    "validLossList = []\n",
    "\n",
    "network.train()\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    ### TRAINING ###\n",
    "    trainLoss = 0\n",
    "    for batch_nr, (images, labels) in enumerate(trainLoader):\n",
    "        \n",
    "        # Onehot label and reshape img\n",
    "        # labels = to_onehot(labels)\n",
    "        # images = images.view(-1,32*32)\n",
    "\n",
    "        # Predict\n",
    "        predictions = network(images)\n",
    "\n",
    "        # Get loss and backpropogate\n",
    "        loss = lossFunction(predictions, labels)\n",
    "        loss.backward() \n",
    "\n",
    "        # Optimize parameters (weights and biases) and remove gradients after\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Save loss for whole epoch\n",
    "        trainLoss += loss.item()\n",
    "\n",
    "    trainLoss /= len(trainLoader)\n",
    "    trainLossList.append(trainLoss)\n",
    "\n",
    "    ### VALIDATION ###\n",
    "    validLoss = 0\n",
    "    for batch_nr, (images, labels) in enumerate(validLoader):\n",
    "        # Onehot label and reshape img\n",
    "        # labels = to_onehot(labels)\n",
    "        # images = images.view(-1,28*28)\n",
    "\n",
    "        # Predict\n",
    "        predictions = network(images)\n",
    "\n",
    "        # Get loss\n",
    "        loss = lossFunction(predictions, labels)\n",
    "\n",
    "        # Save loss for whole epoch\n",
    "        validLoss += loss.item()\n",
    "\n",
    "    validLoss /= len(validLoader)\n",
    "    validLossList.append(validLoss)\n",
    "\n",
    "    # Print reuslt of epoch\n",
    "    print(f'Epoch [{epoch+1}/{epochs}] \\t Training Loss: {trainLoss} \\t Validation Loss: {validLoss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
